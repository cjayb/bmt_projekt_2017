{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maxfilter preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requires `stormdb` v.0.6.1 or greater (run on 0.7.dev0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "### On the structure of the study\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output file and folder names\n",
    "\n",
    "Remember to use the project `scratch` folder for output, and make it easy to clean up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "proj_name = 'MEG_EEG-Training'\n",
    "scratch_folder = join('/projects', proj_name, 'scratch')\n",
    "mf_folder = join(scratch_folder, 'maxfilter', 'VS-meanpos')  # for maxfilter output\n",
    "scripts_folder = join('/projects', proj_name, 'scripts')\n",
    "misc_folder = join('/projects', proj_name, 'misc')\n",
    "trans_folder = join(scratch_folder, 'trans')  # for transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries\n",
    "\n",
    "In Python, we have to load what we need!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from stormdb.access import Query\n",
    "from stormdb.process import Maxfilter\n",
    "from mne.io import Raw\n",
    "from mne.bem import fit_sphere_to_headshape\n",
    "from mne.transforms import rotation_angles, rotation3d, write_trans\n",
    "import warnings\n",
    "import os\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# silence mne a bit\n",
    "from mne.utils import set_log_level\n",
    "set_log_level('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant parameters\n",
    "\n",
    "Place parameters here you might want to play with, such as tSSS buffer length and correlation limit. Output folders will be automatically generated to reflect these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tsss_buffer_len = 60.\n",
    "tsss_corr_lim = 0.96  # don't expect this to make huge diff\n",
    "\n",
    "# if you know that some channels are bad or flat, enter them here\n",
    "# in the form ['2511', '2241']\n",
    "mx_cmd = join(misc_folder, 'bin', 'maxfilter-2.2.15')\n",
    "cal_db = join(misc_folder, 'databases', 'sss_cal.dat')\n",
    "ctc_db = join(misc_folder, 'databases', 'ct_sparse.fif')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the data\n",
    "\n",
    "Instead of accessing raw files directly, use the database query functions to get to files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qr = Query(proj_name)\n",
    "cur_sub = '0012'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the head positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we want to calculate the average initial head position and use movecomp to correct head motion to that origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: /projects/MINDLAB2013_01-MEG-AttentionEmotionVisualTracking/raw/0030/20130918_000000/MEG/002.VS_1b_1/files\n",
      "2: /projects/MINDLAB2013_01-MEG-AttentionEmotionVisualTracking/raw/0030/20130918_000000/MEG/003.VS_1b_2/files\n"
     ]
    }
   ],
   "source": [
    "description = 'run_*'\n",
    "DATAblocks = qr.filter_series(description=description, subjects=cur_sub, modalities='MEG')\n",
    "\n",
    "if len(DATAblocks) != 2:\n",
    "    raise RuntimeError('Not all 2 blocks found for {0}, please check!'.format(cur_sub))\n",
    "for ib in range(len(DATAblocks)):\n",
    "    print('{:d}: {:s}'.format(ib + 1, DATAblocks[ib]['path']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Find initial head positions\n",
    "\n",
    "Get device to head-transformation from the initial HPI fit at the beginning of each acquisition. This consists of a translation and rotation, which are combined in to a single transformation matrix. Since both operations are *affine transformations*, we may simply average the initial matrices to obtain the mean head position and rotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This filename (/raw/sorted/MINDLAB2013_01-MEG-AttentionEmotionVisualTracking/0030/20130918_000000/MEG/002.VS_1b_1/files/PROJ0103_SUBJ0030_SER002_FILESNO001.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, raw.fif.gz, raw_sss.fif.gz or raw_tsss.fif.gz\n",
      "This filename (/raw/sorted/MINDLAB2013_01-MEG-AttentionEmotionVisualTracking/0030/20130918_000000/MEG/003.VS_1b_2/files/PROJ0103_SUBJ0030_SER003_FILESNO001.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, raw.fif.gz, raw_sss.fif.gz or raw_tsss.fif.gz\n"
     ]
    }
   ],
   "source": [
    "init_xfm = []\n",
    "init_rot = []\n",
    "data_len = []\n",
    "for bl in DATAblocks:\n",
    "    fname = join(bl['path'], bl['files'][0])  # first file is enough\n",
    "    with warnings.catch_warnings():  # suppress some annoying warnings for now\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        raw = Raw(fname, preload=False, verbose=False)\n",
    "        data_len += [len(raw)/raw.info['sfreq']]\n",
    "\n",
    "    init_xfm += [raw.info['dev_head_t']['trans']]\n",
    "    # translations: info['dev_head_t']['trans'][:, 3][:-1]\n",
    "    init_rot += [raw.info['dev_head_t']['trans'][:3, :3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the average head position and calculate how far each block is from it (look for outliers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_init_xfm = np.mean(np.stack(init_xfm), axis=0)  # stack, then average over new dim\n",
    "init_rot_angles = [rotation_angles(m) for m in init_rot]\n",
    "\n",
    "mean_init_rot_xfm = rotation3d(*tuple(np.mean(np.stack(init_rot_angles),\n",
    "                                              axis=0)))  # stack, then average, then make new xfm\n",
    "\n",
    "assert(np.sum(mean_init_xfm[-1]) == 1.0)  # sanity check result\n",
    "mean_trans = info['dev_head_t']  # use the last info as a template\n",
    "mean_trans['trans'] = mean_init_xfm  # replace the transformation\n",
    "mean_trans['trans'][:3, :3] = mean_init_rot_xfm  # replace the rotation part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the mean position in mm and each block's discrepancy from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean head position (device coords): (7.5, 2.3, 62.1) mm\n",
      "Block discrepancies from mean:\n",
      "\tblock 1: norm 1.9 mm (-1.7, -0.4, -0.8) mm \n",
      "\tblock 2: norm 1.9 mm (1.7, 0.4, 0.8) mm \n"
     ]
    }
   ],
   "source": [
    "mean_init_headpos = mean_trans['trans'][:-1, -1]  # meters\n",
    "print('Mean head position (device coords): ({:.1f}, {:.1f}, {:.1f}) mm'.\\\n",
    "      format(*tuple(mean_init_headpos*1e3)))\n",
    "print('Block discrepancies from mean:')\n",
    "for ib, xfm in enumerate(init_xfm):\n",
    "    diff = 1e3 * (xfm[:-1, -1] - mean_init_headpos)\n",
    "    rmsdiff = np.linalg.norm(diff)\n",
    "    print('\\tblock {:d}: norm {:.1f} mm ({:.1f}, {:.1f}, {:.1f}) mm '.\\\n",
    "          format(ib + 1, rmsdiff, *tuple(diff)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean head rotations (around x, y & z axes): (-6.8, 1.8, 2.7) deg\n",
      "Block discrepancies from mean:\n",
      "\tblock 1: (1.7, -0.6, 0.4) deg \n",
      "\tblock 2: (-1.7, 0.6, -0.4) deg \n"
     ]
    }
   ],
   "source": [
    "mean_rots = rotation_angles(mean_trans['trans'][:3, :3])  # these are in radians\n",
    "mean_rots_deg = tuple([180. * rot / np.pi for rot in mean_rots])  # convert to deg\n",
    "print('Mean head rotations (around x, y & z axes): ({:.1f}, {:.1f}, {:.1f}) deg'.\\\n",
    "      format(*mean_rots_deg))\n",
    "print('Block discrepancies from mean:')\n",
    "for ib, rot in enumerate(init_rot):   \n",
    "    cur_rots = rotation_angles(rot)\n",
    "    diff = tuple([180. * cr / np.pi - mr for cr, mr in zip(cur_rots, mean_rots_deg)])\n",
    "    print('\\tblock {:d}: ({:.1f}, {:.1f}, {:.1f}) deg '.\\\n",
    "          format(ib + 1, *tuple(diff)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the new mean transformation to a file to be used later in the `maxfilter`-option `trans`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_trans_folder = join(trans_folder, cur_sub)\n",
    "if not os.path.exists(mean_trans_folder):\n",
    "    os.makedirs(mean_trans_folder)\n",
    "mean_trans_file = join(mean_trans_folder, 'mean-trans.fif')\n",
    "write_trans(mean_trans_file, mean_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit head origin for SSS expansion\n",
    "\n",
    "any info (from this study) will do, since the digitization points are the same for all blocks; take the last one from for-loop above. NB: Only use EEG locations, since head points only on face!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted sphere radius:         90.2 mm\n",
      "Origin head coordinates:      1.0 13.1 48.3 mm\n",
      "Origin device coordinates:    -5.5 12.6 -12.6 mm\n"
     ]
    }
   ],
   "source": [
    "set_log_level('INFO')\n",
    "rad, origin_head, ori_dev = fit_sphere_to_headshape(info,\n",
    "                                                    dig_kinds='extra',\n",
    "                                                    units='mm')\n",
    "set_log_level('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate Maxfilter-object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mf = Maxfilter(proj_name, bad=sub_specific_bad_chans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build maxfilter commands for all the blocks\n",
    "\n",
    "First set some of the options (leave others as default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mfopts = dict(\n",
    "    origin = '{:.1f} {:.1f} {:.1f}'.format(*tuple(origin_head)),  # mm\n",
    "    frame = 'head',\n",
    "    force = True,  # overwrite if needed\n",
    "    autobad = 'on',  # or use xscan first\n",
    "    st = True,  # use tSSS\n",
    "    st_buflen = tsss_buffer_len,  # parameter set in beg. of notebook\n",
    "    st_corr = tsss_corr_lim,  # parameter set in beg. of notebook\n",
    "    movecomp = True,\n",
    "    trans = mean_trans_file,  # compensate to mean initial head position (saved to file),\n",
    "                              # use None for initial head position\n",
    "    logfile = None,  # we replace this in each loop\n",
    "    hp = None,  # head positions, replace in each loop\n",
    "    n_threads = 4  # antal kerner på isis, max 12, være solidarisk!\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mne-python likes raw and raw-like (tsss) files that are part of a long (>2GB) continuous acquisition to follow the convention:\n",
    "\n",
    "1. `filename_raw_tsss.fif` (first file)\n",
    "1. `filename_raw_tsss-1.fif` (second file, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_folder = join(mf_folder,\n",
    "                  'tsss_st{:.0f}_corr{:.0f}'.format(mfopts['st_buflen'],\n",
    "                                                  np.round(100 * mfopts['st_corr'])),\n",
    "                  cur_sub)\n",
    "\n",
    "# Check that output path exists\n",
    "if not os.path.exists(out_folder):\n",
    "    os.makedirs(out_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for blockno, bl in enumerate(DATAblocks):\n",
    "    for fileno, fil in enumerate(bl['files']):\n",
    "        in_fname = join(bl['path'], bl['files'][fileno])\n",
    "        \n",
    "        series_name = re.search('(run_1|run_2|run_3)',\n",
    "                                bl['seriename']).group(1)\n",
    "        \n",
    "        out_fname = join(out_folder, '{0}_raw_tsss.fif'.format(series_name))\n",
    "        if fileno > 0:\n",
    "            out_fname = out_fname[:-4] + '-{:d}.fif'.format(fileno)\n",
    "           \n",
    "        mfopts['logfile'] = out_fname[:-3] + 'log'\n",
    "        mfopts['hp'] = out_fname[:-3] + 'pos'\n",
    "        \n",
    "        mf.build_cmd(in_fname, out_fname, **mfopts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit to isis for processing\n",
    "\n",
    "First check that you think sane things will happen, if you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projects/MINDLAB2013_01-MEG-AttentionEmotionVisualTracking/raw/0030/20130918_000000/MEG/002.VS_1b_1/files/PROJ0103_SUBJ0030_SER002_FILESNO001.fif\n",
      "\t--> /projects/MINDLAB2013_01-MEG-AttentionEmotionVisualTracking/scratch/maxfilter/VS-meanpos/tsss_st60_corr96/0030_WAH/VS_1b_1_raw_tsss.fif\n",
      "/projects/MINDLAB2013_01-MEG-AttentionEmotionVisualTracking/raw/0030/20130918_000000/MEG/003.VS_1b_2/files/PROJ0103_SUBJ0030_SER003_FILESNO001.fif\n",
      "\t--> /projects/MINDLAB2013_01-MEG-AttentionEmotionVisualTracking/scratch/maxfilter/VS-meanpos/tsss_st60_corr96/0030_WAH/VS_1b_2_raw_tsss.fif\n"
     ]
    }
   ],
   "source": [
    "mf.print_input_output_mapping()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If in doubt, uncomment this line to see the actual commands that will execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'/neuro/bin/util/maxfilter -f /projects/MINDLAB2013_01-MEG-AttentionEmotionVisualTracking/raw/0030/20130918_000000/MEG/002.VS_1b_1/files/PROJ0103_SUBJ0030_SER002_FILESNO001.fif -o /projects/MINDLAB2013_01-MEG-AttentionEmotionVisualTracking/scratch/maxfilter/VS-meanpos/tsss_st60_corr96/0030_WAH/VS_1b_1_raw_tsss.fif -v  -frame head -origin 1.0 13.1 48.3 -v -autobad on -force -st  60 -corr 0.9600 -trans /projects/MINDLAB2013_01-MEG-AttentionEmotionVisualTracking/scratch/trans/0030_WAH/VS_mean-trans.fif -movecomp -hp /projects/MINDLAB2013_01-MEG-AttentionEmotionVisualTracking/scratch/maxfilter/VS-meanpos/tsss_st60_corr96/0030_WAH/VS_1b_1_raw_tsss.pos -hpicons  | tee /projects/MINDLAB2013_01-MEG-AttentionEmotionVisualTracking/scratch/maxfilter/VS-meanpos/tsss_st60_corr96/0030_WAH/VS_1b_1_raw_tsss.log',\n",
       " u'/neuro/bin/util/maxfilter -f /projects/MINDLAB2013_01-MEG-AttentionEmotionVisualTracking/raw/0030/20130918_000000/MEG/003.VS_1b_2/files/PROJ0103_SUBJ0030_SER003_FILESNO001.fif -o /projects/MINDLAB2013_01-MEG-AttentionEmotionVisualTracking/scratch/maxfilter/VS-meanpos/tsss_st60_corr96/0030_WAH/VS_1b_2_raw_tsss.fif -v  -frame head -origin 1.0 13.1 48.3 -v -autobad on -force -st  60 -corr 0.9600 -trans /projects/MINDLAB2013_01-MEG-AttentionEmotionVisualTracking/scratch/trans/0030_WAH/VS_mean-trans.fif -movecomp -hp /projects/MINDLAB2013_01-MEG-AttentionEmotionVisualTracking/scratch/maxfilter/VS-meanpos/tsss_st60_corr96/0030_WAH/VS_1b_2_raw_tsss.pos -hpicons  | tee /projects/MINDLAB2013_01-MEG-AttentionEmotionVisualTracking/scratch/maxfilter/VS-meanpos/tsss_st60_corr96/0030_WAH/VS_1b_2_raw_tsss.log']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: What is the cluster doing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mf.cluster.get_load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ready to rock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster job submitted, job ID: 3863818\n",
      "Cluster job submitted, job ID: 3863819\n"
     ]
    }
   ],
   "source": [
    "mf.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking what's going on\n",
    "\n",
    "In a terminal:\n",
    "\n",
    "```\n",
    "qstat\n",
    "```\n",
    "\n",
    "shows all running jobs (in your name). For _every/anyone's_ jobs, run\n",
    "\n",
    "```\n",
    "qstat -u \"*\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 (3863818): Waiting in the queue\n",
      "#2 (3863819): Waiting in the queue\n"
     ]
    }
   ],
   "source": [
    "mf.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To kill a submitted (or even running) job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 3511711 killed. You must manually delete any output it may have created!\n"
     ]
    }
   ],
   "source": [
    "# mf.kill(3511711)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To kill all submitted jobs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mf.kill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To kill a job in the shell:\n",
    "\n",
    "```\n",
    "qdel JOB_NUMBER\n",
    "```\n",
    "\n",
    "or for all jobs (in your name):\n",
    "\n",
    "```\n",
    "qdel *\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    mf_list\n",
    "except NameError:\n",
    "    mf_list = []\n",
    "mf_list += [mf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 (3511710): Waiting in the queue\n",
      "#2 (3511711): Waiting in the queue\n",
      "#3 (3511712): Waiting in the queue\n",
      "#4 (3511713): Waiting in the queue\n",
      "#5 (3511714): Waiting in the queue\n",
      "#6 (3511715): Waiting in the queue\n",
      "#1 (3511710): Waiting in the queue\n",
      "#2 (3511711): Waiting in the queue\n",
      "#3 (3511712): Waiting in the queue\n",
      "#4 (3511713): Waiting in the queue\n",
      "#5 (3511714): Waiting in the queue\n",
      "#6 (3511715): Waiting in the queue\n"
     ]
    }
   ],
   "source": [
    "for cur_mf in mf_list:\n",
    "    cur_mf.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
