{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing directories and setting filepath\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file /Users/nielskjaergaardmadsen/Documents/CFIN/Data/bmt_cleaned/run_3_raw_sss.fif...\n",
      "    Range : 50000 ... 807999 =     50.000 ...   807.999 secs\n",
      "Ready.\n",
      "Current compensation grade : 0\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/Users/nielskjaergaardmadsen/Documents/CFIN/Data/bmt_cleaned/run_3_raw_sss.fif\"\n",
    "raw = mne.io.read_raw_fif(data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find events, filter & plot data\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3737 events found\n",
      "Events id: [ 10 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135\n",
      " 136]\n"
     ]
    }
   ],
   "source": [
    "events = mne.find_events(raw, min_duration=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "event_id = {'Start':10,\n",
    "           'Q1/1':101,'Q1/2':102,'Q1/3':103,'Q2/1':104,'Q2/2':105,'Q2/3':106,\n",
    "           'Q3/1':107,'Q3/2':108,'Q3/3':109,'Q4/1':110,'Q4/2':111,'Q4/3':112,\n",
    "           'Q1/4':113,'Q1/5':114,'Q1/6':115,'Q2/4':116,'Q2/5':117,'Q2/6':118,\n",
    "           'Q3/4':119,'Q3/5':120,'Q3/6':121,'Q4/4':122,'Q4/5':123,'Q4/6':124,\n",
    "           'Q1/7':125,'Q1/8':126,'Q1/9':127,'Q2/7':128,'Q2/8':129,'Q2/9':130,\n",
    "           'Q3/7':131,'Q3/8':132,'Q3/9':133,'Q4/7':134,'Q4/8':135,'Q4/9':136}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 757999  =      0.000 ...   757.999 secs...\n",
      "Setting up band-pass filter from 1 - 40 Hz\n",
      "fir_design defaults to \"firwin2\" in 0.15 but will change to \"firwin\" in 0.16, set it explicitly to avoid this warning.\n",
      "l_trans_bandwidth chosen to be 1.0 Hz\n",
      "h_trans_bandwidth chosen to be 10.0 Hz\n",
      "Filter length of 6600 samples (6.600 sec) selected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-bc46e17f4378>:3: DeprecationWarning: fir_design defaults to \"firwin2\" in 0.15 but will change to \"firwin\" in 0.16, set it explicitly to avoid this warning.\n",
      "  raw.filter(l_freq, h_freq)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Raw  |  run_3_raw_sss.fif, n_channels x n_times : 323 x 758000 (758.0 sec), ~1.83 GB, data loaded>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_freq, h_freq = 1,40\n",
    "raw.load_data()\n",
    "raw.filter(l_freq, h_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw.plot(order='selection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw.plot?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find epochs\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmin, tmax = -0.05, 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseline = None\n",
    "reject = {'mag':4e-12}\n",
    "#epochs = mne.Epochs(raw, events=events,baseline = baseline, event_id=event_id, tmin=tmin,\n",
    " #                   tmax=tmax, reject=reject, preload=True,detrend = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs.plot(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs.plot_drop_log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find evoked Q1\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q1\n",
    "ts_args = dict(gfp=True)\n",
    "topomap_args = dict(sensors=False)\n",
    "x = 0\n",
    "fig, ax = plt.subplots(9,4)\n",
    "event_Q1_id = {'Q1/1':101,'Q1/2':102,'Q1/3':103,'Q1/4':113,'Q1/5':114,'Q1/6':115,\n",
    "              'Q1/7':124,'Q1/8':125,'Q1/9':126}\n",
    "times = [0.035, 0.085, 0.135, 0.2] # 0.2 is not in use\n",
    "for key in event_Q1_id.keys():\n",
    "    evoked = epochs[key].average()\n",
    "    #if x==8:\n",
    "    print(key)\n",
    "    evoked.plot_topomap(times = times,axes=ax[x], show=True)\n",
    "        #evoked.plot(exclude=(),axes = ax2[x])\n",
    "    #evoked.plot_joint(title=key, times=[0.035, 0.085, 0.135],ts_args=ts_args, topomap_args=topomap_args)\n",
    "    #else:\n",
    "        #evoked.plot_topomap(times = times[0],axes=ax[x], show=False)\n",
    "        #evoked.plot_topomap(times = times[1],axes=ax2[x], show=False)\n",
    " \n",
    "        #evoked.plot(exclude=(),axes = ax2[x])\n",
    "        \n",
    "    x +=1\n",
    "    print('Calculating')\n",
    "    if x==9:\n",
    "        \n",
    "        print('Breaking')\n",
    "        break\n",
    "    \n",
    "\n",
    "#evoked_Q1_4 = epochs['Q1/2'].average()\n",
    "#evoked_Q1_7 = epochs['Q1/3'].average()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Evoked Q2\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q2\n",
    "ts_args = dict(gfp=True)\n",
    "topomap_args = dict(sensors=False)\n",
    "x = 0\n",
    "fig, ax = plt.subplots(9,4)\n",
    "event_Q2_id = {'Q2/1':104,'Q2/2':105,'Q2/3':106,\n",
    "               'Q2/4':116,'Q2/5':117,'Q2/6':118,\n",
    "               'Q2/7':127,'Q2/8':128,'Q2/9':129}\n",
    "times = [0.035, 0.085, 0.135, 0.2] # 0.2 is not in use\n",
    "for key in event_Q2_id.keys():\n",
    "    evoked = epochs[key].average()\n",
    "    #if x==8:\n",
    "    evoked.plot_topomap(times = times,axes=ax[x], show=True)\n",
    "        #evoked.plot(exclude=(),axes = ax2[x])\n",
    "    #evoked.plot_joint(title=key, times=[0.035, 0.085, 0.135],ts_args=ts_args, topomap_args=topomap_args)\n",
    "    #else:\n",
    "        #evoked.plot_topomap(times = times[0],axes=ax[x], show=False)\n",
    "        #evoked.plot_topomap(times = times[1],axes=ax2[x], show=False)\n",
    " \n",
    "        #evoked.plot(exclude=(),axes = ax2[x])\n",
    "        \n",
    "    x +=1\n",
    "    print('Calculating')\n",
    "    if x==9:\n",
    "        \n",
    "        print('Breaking')\n",
    "        break\n",
    "    \n",
    "\n",
    "#evoked_Q1_4 = epochs['Q1/2'].average()\n",
    "#evoked_Q1_7 = epochs['Q1/3'].average()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find evoked all\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for var in sorted_:\n",
    " a = var\n",
    " print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evoked.plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts_args = dict(gfp=True)\n",
    "topomap_args = dict(sensors=False)\n",
    "\n",
    "\n",
    "sorted_ = sorted(event_id.items(), key=operator.itemgetter(1))\n",
    "sorted_.remove(('Start', 10))\n",
    "times = [0.085]\n",
    "fig, ax = plt.subplots(9,1)\n",
    "fig2, ax2 = plt.subplots(3,2)\n",
    "plt.tight_layout()\n",
    "x = 0\n",
    "y = 0\n",
    "quadrant = 0 # 0 for Q1, 3 for Q2, 6 for Q3 and 9 for Q4\n",
    "for i in range(0, 3):\n",
    "    for ii in range(0, 3): \n",
    "        if i > 0:\n",
    "\n",
    "            ind = ii+6*y+quadrant\n",
    "            print(ind)\n",
    "            key = sorted_[ind]\n",
    "            print(key[0])\n",
    "            evoked = epochs[key[0]].average()\n",
    "            #evoked.plot(gfp=True,axes = ax2[x])\n",
    "            evoked.plot_topomap(times = times,axes=ax[x], show=False,colorbar = False, title='Q1')\n",
    "            x +=1            \n",
    "            \n",
    "        else:\n",
    "            \n",
    "            ind = ii+quadrant\n",
    "            print(ind)\n",
    "            key = sorted_[ind]\n",
    "            print(key[0])\n",
    "            evoked = epochs[key[0]].average()\n",
    "            evoked.plot(gfp=True,axes = ax2[x])\n",
    "            evoked.plot_topomap(times = times,axes=ax[x], show=False,colorbar = False)\n",
    "            x +=1\n",
    "    y += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times = np.arange(0.05, 0.15, 0.01)\n",
    "\n",
    "evoked.plot_topomap(times, ch_type='grad')\n",
    "fig, anim = evoked.animate_topomap(ch_type='mag', times=times, frame_rate=10)\n",
    "evoked.plot_topomap(0.1, ch_type='grad', show_names=True, colorbar=False,\n",
    "                    size=6, res=128, title='Visual respons')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = evoked_Q1_1.plot(exclude=())\n",
    "fig2 = evoked_Q2_1.plot(exclude=())\n",
    "fig3 = evoked_Q3_1.plot(exclude=())\n",
    "fig4 = evoked_Q4_1.plot(exclude=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts_args = dict(gfp=True)\n",
    "topomap_args = dict(sensors=False)\n",
    "#evoked_Q1_1.plot_joint(title='Q1/2', times=[0.035, 0.085, 0.135],\n",
    "                        #ts_args=ts_args, topomap_args=topomap_args)\n",
    "#evoked_Q2_1.plot_joint(title='Q2/2', times=[0.035, 0.085, 0.135],\n",
    " #                       ts_args=ts_args, topomap_args=topomap_args)\n",
    "#evoked_Q3_1.plot_joint(title='Q3/2', times=[0.035, 0.085, 0.135],\n",
    " #                       ts_args=ts_args, topomap_args=topomap_args)\n",
    "#evoked_Q4_1.plot_joint(title='Q4/2', times=[0.035, 0.085, 0.135],\n",
    "                       # ts_args=ts_args, topomap_args=topomap_args)\n",
    "evoked_Q1_9 = epochs['Q1/9'].average()\n",
    "evoked_Q1_9.plot_joint(title='Q1/9', times=[0.035, 0.085, 0.135],\n",
    "                        ts_args=ts_args, topomap_args=topomap_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evoked_Q1_1.plot_topomap(times = 'peaks', title = 'Q1/1')\n",
    "\n",
    "evoked_Q1_4.plot_topomap(times = 'peaks', title = 'Q1/4')\n",
    "\n",
    "evoked_Q1_7.plot_topomap(times = 'peaks', title = 'Q1/7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evoked_Q2_1.plot_topomap(times = 'peaks', title = 'Q2/1')\n",
    "\n",
    "evoked_Q2_4.plot_topomap(times = 'peaks', title = 'Q2/4')\n",
    "\n",
    "evoked_Q2_7.plot_topomap(times = 'peaks', title = 'Q2/7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evoked_Q3_1.plot_topomap(times = 'peaks', title = 'Q3/1')\n",
    "\n",
    "evoked_Q4_1.plot_topomap(times = 'peaks', title = 'Q4/1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequency\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw.plot_psd(tmax=np.inf, fmax=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs.plot_psd(fmin=1., fmax=40.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs.plot_psd_topomap(ch_type='grad', normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "3D \n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subjects_dir = data_path + '/subjects'\n",
    "trans_fname = data_path + '/MEG/sample/sample_audvis_raw-trans.fif'\n",
    "\n",
    "maps = mne.make_field_map(evoked_Q1_1, trans=trans_fname, subject='sample',\n",
    "                          subjects_dir=subjects_dir, n_jobs=1)\n",
    "\n",
    "# explore several points in time\n",
    "field_map = evoked_Q1_1.plot_field(maps, time=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw.plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Machine Learning for Dummies\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mne import merge_events\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import mne\n",
    "from mne.datasets import sample\n",
    "from mne.decoding import (SlidingEstimator, GeneralizingEstimator,\n",
    "                          cross_val_multiscore, LinearModel, get_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([104, 105, 106, 107, 108, 109, 116, 117, 118, 119, 120, 121, 128,\n",
       "       129, 130, 131, 132, 133])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_id = np.arange(101,137,1).reshape(12, 3)\n",
    "upper_id = tmp_id[[0,3,4,7,8,11],:].ravel()\n",
    "lower_id= tmp_id[[1,2,5,6,9,10],:].ravel()\n",
    "upper_id\n",
    "lower_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "new_events = events.copy()\n",
    "y = 0\n",
    "for x in events:\n",
    "    \n",
    "    val = x[2]\n",
    "    if val in upper_id:\n",
    "        new_events[y][2] = 1\n",
    "        \n",
    "    elif val in lower_id:\n",
    "        new_events[y][2] = 2\n",
    "    \n",
    "    y += 1\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst = mne.merge_events(events, lower_id, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[65238,     0,    10],\n",
       "       [65639,    10,     2],\n",
       "       [65738,     0,   135],\n",
       "       [65838,     0,     2],\n",
       "       [65938,     0,     2],\n",
       "       [66038,     0,   126],\n",
       "       [66138,     0,     2],\n",
       "       [66238,     0,     2],\n",
       "       [66338,     0,   123],\n",
       "       [66438,     0,   110],\n",
       "       [66539,     0,   127],\n",
       "       [66639,     0,     2],\n",
       "       [66739,     0,   113],\n",
       "       [66839,     0,   114],\n",
       "       [66939,     0,     2],\n",
       "       [67039,     0,     2],\n",
       "       [67139,     0,   111],\n",
       "       [67239,     0,     2],\n",
       "       [67339,     0,   122],\n",
       "       [67439,     0,     2]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 65238,      0,     10],\n",
       "       [ 65639,     10,      2],\n",
       "       [ 65738,      0,      1],\n",
       "       ..., \n",
       "       [792785,      0,      2],\n",
       "       [792885,      0,      1],\n",
       "       [792985,      0,      1]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3636 matching events found\n",
      "0 projection items activated\n",
      "Loading data for 3636 events and 251 original time points ...\n",
      "    Rejecting  epoch based on EOG : [u'EOG003']\n",
      "    Rejecting  epoch based on EOG : [u'EOG003']\n",
      "    Rejecting  epoch based on EOG : [u'EOG003']\n",
      "3 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "new_event_id = dict(upper=1, lower=2)\n",
    "epochs_MVP = mne.Epochs(raw = raw, events = new_events,event_id = new_event_id, tmin = tmin, tmax = tmax, proj=True,\n",
    "                     baseline=None, detrend = 0, preload=True,\n",
    "                    reject=reject, decim=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = epochs_MVP.get_data()  # MEG signals: n_epochs, n_channels, n_times\n",
    "y = epochs_MVP.events[:, 2]  # target: Upper or lower\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "time_decod = SlidingEstimator(clf, n_jobs=1, scoring='roc_auc')\n",
    "\n",
    "scores = cross_val_multiscore(time_decod, X, y, cv=5, n_jobs=1)\n",
    "\n",
    "# Mean scores across cross-validation splits\n",
    "scores = np.mean(scores, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63,)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(epochs_MVP.times, scores, label='score')\n",
    "ax.axhline(.5, color='k', linestyle='--', label='chance')\n",
    "ax.set_xlabel('Times')\n",
    "ax.set_ylabel('AUC')  # Area Under the Curve\n",
    "ax.legend()\n",
    "ax.axvline(.0, color='k', linestyle='-')\n",
    "ax.set_title('Sensor space decoding')\n",
    "plt.show()\n",
    "\n",
    "# You can retrieve the spatial filters and spatial patterns if you explicitly\n",
    "# use a LinearModel\n",
    "clf = make_pipeline(StandardScaler(), LinearModel(LogisticRegression()))\n",
    "time_decod = SlidingEstimator(clf, n_jobs=1, scoring='roc_auc')\n",
    "time_decod.fit(X, y)\n",
    "\n",
    "coef = get_coef(time_decod, 'patterns_', inverse_transform=True)\n",
    "evoked = mne.EvokedArray(coef, epochs_MVP.info, tmin=epochs_MVP.times[0])\n",
    "evoked.plot_joint(times=np.arange(0.,0.2,.50), title='patterns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the Temporal Generalization object\n",
    "time_gen = GeneralizingEstimator(clf, n_jobs=1, scoring='roc_auc')\n",
    "\n",
    "scores = cross_val_multiscore(time_gen, X, y, cv=5, n_jobs=1)\n",
    "\n",
    "# Mean scores across cross-validation splits\n",
    "scores = np.mean(scores, axis=0)\n",
    "\n",
    "# Plot the diagonal (it's exactly the same as the time-by-time decoding above)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(epochs_MVP.times, np.diag(scores), label='score')\n",
    "ax.axhline(.5, color='k', linestyle='--', label='chance')\n",
    "ax.set_xlabel('Times')\n",
    "ax.set_ylabel('AUC')\n",
    "ax.legend()\n",
    "ax.axvline(.0, color='k', linestyle='-')\n",
    "ax.set_title('Decoding MEG sensors over time')\n",
    "plt.show()\n",
    "\n",
    "# Plot the full matrix\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "im = ax.imshow(scores, interpolation='lanczos', origin='lower', cmap='RdBu_r',\n",
    "               extent=epochs_MVP.times[[0, -1, 0, -1]], vmin=0., vmax=1.)\n",
    "ax.set_xlabel('Testing Time (s)')\n",
    "ax.set_ylabel('Training Time (s)')\n",
    "ax.set_title('Temporal Generalization Upper/Lower')\n",
    "ax.axvline(0, color='k')\n",
    "ax.axhline(0, color='k')\n",
    "plt.colorbar(im, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadrants MVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_id_Q = np.arange(101,137,1).reshape(12, 3)\n",
    "Q1_id = tmp_id_Q[[0,4,8],:].ravel()\n",
    "Q2_id = tmp_id_Q[[1,5,9],:].ravel()\n",
    "Q3_id = tmp_id_Q[[2,6,10],:].ravel()\n",
    "Q4_id = tmp_id_Q[[3,7,11],:].ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lower_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9fbf80862211>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lower_id' is not defined"
     ]
    }
   ],
   "source": [
    "tst = mne.merge_events(events, lower_id, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "new_events_Q = mne.merge_events(events, Q1_id, 1)\n",
    "new_events_Q = mne.merge_events(new_events_Q, Q2_id, 2)\n",
    "new_events_Q = mne.merge_events(new_events_Q, Q3_id, 3)\n",
    "new_events_Q = mne.merge_events(new_events_Q, Q4_id, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3636 matching events found\n",
      "0 projection items activated\n",
      "Loading data for 3636 events and 251 original time points ...\n",
      "    Rejecting  epoch based on EOG : [u'EOG003']\n",
      "    Rejecting  epoch based on EOG : [u'EOG003']\n",
      "    Rejecting  epoch based on EOG : [u'EOG003']\n",
      "3 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "new_event_Q_id = dict(Q1=1, Q2=2, Q3=3, Q4=4)\n",
    "epochs_MVP_Q = mne.Epochs(raw = raw, events = new_events_Q,event_id = new_event_Q_id, tmin = tmin, tmax = tmax, proj=True,\n",
    "                     baseline=None, detrend = 0, preload=True,\n",
    "                    reject=reject, decim=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = epochs_MVP_Q.get_data()  # MEG signals: n_epochs, n_channels, n_times\n",
    "y = epochs_MVP_Q.events[:, 2]  # target: Q1, Q2, Q3, Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scoring_function1 = 'roc_auc'\n",
    "scoring_function2 = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLF done\n",
      "Time decode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  5.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores\n",
      "Plotting\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "print('CLF done')\n",
    "\n",
    "# time_decod = SlidingEstimator(clf, n_jobs=1, scoring='roc_auc')\n",
    "time_decod = SlidingEstimator(clf, n_jobs=1, scoring=scoring_function2)\n",
    "\n",
    "print('Time decode')\n",
    "scores = cross_val_multiscore(time_decod, X, y, cv=5, n_jobs=2)\n",
    "\n",
    "print('Mean scores')\n",
    "# Mean scores across cross-validation splits\n",
    "scores = np.mean(scores, axis=0)\n",
    "\n",
    "print('Plotting')\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(epochs_MVP_Q.times, scores, label='score')\n",
    "ax.axhline(.5, color='k', linestyle='--', label='chance')\n",
    "ax.set_xlabel('Times')\n",
    "ax.set_ylabel('AUC')  # Area Under the Curve\n",
    "ax.legend()\n",
    "ax.axvline(.0, color='k', linestyle='-')\n",
    "ax.set_title('Sensor space decoding')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data must be a 2D array of shape (n_channels, n_samples)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-8df0627ff597>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcoef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_coef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_decod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'patterns_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mevoked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvokedArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_MVP_Q\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs_MVP_Q\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mevoked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_joint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'patterns'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nielskjaergaardmadsen/mne-python/mne/evoked.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, info, tmin, comment, nave, kind, verbose)\u001b[0m\n",
      "\u001b[0;32m/Users/nielskjaergaardmadsen/mne-python/mne/utils.pyc\u001b[0m in \u001b[0;36mverbose\u001b[0;34m(function, *args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0muse_log_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nielskjaergaardmadsen/mne-python/mne/evoked.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, info, tmin, comment, nave, kind, verbose)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m             raise ValueError('Data must be a 2D array of shape (n_channels, '\n\u001b[0m\u001b[1;32m    734\u001b[0m                              'n_samples)')\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data must be a 2D array of shape (n_channels, n_samples)"
     ]
    }
   ],
   "source": [
    "# You can retrieve the spatial filters and spatial patterns if you explicitly\n",
    "# use a LinearModel\n",
    "clf = make_pipeline(StandardScaler(), LinearModel(LogisticRegression()))\n",
    "time_decod = SlidingEstimator(clf, n_jobs=1, scoring='roc_auc')\n",
    "time_decod.fit(X, y)\n",
    "\n",
    "coef = get_coef(time_decod, 'patterns_', inverse_transform=True)\n",
    "evoked = mne.EvokedArray(coef, epochs_MVP_Q.info, tmin=epochs_MVP_Q.times[0])\n",
    "evoked.plot_joint(times=np.arange(0.,0.2,.50), title='patterns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the Temporal Generalization object\n",
    "time_gen = GeneralizingEstimator(clf, n_jobs=1, scoring=scoring_function)\n",
    "\n",
    "scores = cross_val_multiscore(time_gen, X, y, cv=5, n_jobs=1)\n",
    "\n",
    "# Mean scores across cross-validation splits\n",
    "scores = np.mean(scores, axis=0)\n",
    "\n",
    "# Plot the diagonal (it's exactly the same as the time-by-time decoding above)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(epochs_MVP_Q.times, np.diag(scores), label='score')\n",
    "ax.axhline(.5, color='k', linestyle='--', label='chance')\n",
    "ax.set_xlabel('Times')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend()\n",
    "ax.axvline(.0, color='k', linestyle='-')\n",
    "ax.set_title('Decoding MEG sensors over time in quadrants')\n",
    "plt.show()\n",
    "\n",
    "# Plot the full matrix\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "im = ax.imshow(scores, interpolation='lanczos', origin='lower', cmap='RdBu_r',\n",
    "               extent=epochs_MVP_Q.times[[0, -1, 0, -1]], vmin=0., vmax=1.)\n",
    "ax.set_xlabel('Testing Time (s)')\n",
    "ax.set_ylabel('Training Time (s)')\n",
    "ax.set_title('Temporal Generalization')\n",
    "ax.axvline(0, color='k')\n",
    "ax.axhline(0, color='k')\n",
    "plt.colorbar(im, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 and Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_id_Q = np.arange(101,137,1).reshape(12, 3)\n",
    "Q1_id = tmp_id_Q[[0,4,8],:].ravel()\n",
    "Q2_id = tmp_id_Q[[1,5,9],:].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_events_Q12 = mne.merge_events(events, Q1_id, 1)\n",
    "new_events_Q12 = mne.merge_events(new_events_Q12, Q2_id, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1818 matching events found\n",
      "0 projection items activated\n",
      "Loading data for 1818 events and 251 original time points ...\n",
      "    Rejecting  epoch based on EOG : [u'EOG003']\n",
      "    Rejecting  epoch based on EOG : [u'EOG003']\n",
      "    Rejecting  epoch based on EOG : [u'EOG003']\n",
      "3 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "new_event_Q12_id = dict(Q1=1, Q2=2)\n",
    "epochs_MVP_Q12 = mne.Epochs(raw = raw, events = new_events_Q12,event_id = new_event_Q12_id, tmin = tmin, tmax = tmax, proj=True,\n",
    "                     baseline=None, detrend = 0, preload=True,\n",
    "                    reject=reject, decim=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = epochs_MVP_Q12.get_data()  # MEG signals: n_epochs, n_channels, n_times\n",
    "y = epochs_MVP_Q12.events[:, 2]  # target: Q1, Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.5min finished\n"
     ]
    }
   ],
   "source": [
    "# define the Temporal Generalization object\n",
    "time_gen = GeneralizingEstimator(clf, n_jobs=1, scoring=scoring_function)\n",
    "\n",
    "scores = cross_val_multiscore(time_gen, X, y, cv=5, n_jobs=2)\n",
    "\n",
    "# Mean scores across cross-validation splits\n",
    "scores = np.mean(scores, axis=0)\n",
    "\n",
    "# Plot the diagonal (it's exactly the same as the time-by-time decoding above)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(epochs_MVP_Q12.times, np.diag(scores), label='score')\n",
    "ax.axhline(.5, color='k', linestyle='--', label='chance')\n",
    "ax.set_xlabel('Times')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend()\n",
    "ax.axvline(.0, color='k', linestyle='-')\n",
    "ax.set_title('Decoding MEG sensors over time in quadrants')\n",
    "plt.show()\n",
    "\n",
    "# Plot the full matrix\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "im = ax[x].imshow(scores, interpolation='lanczos', origin='lower', cmap='RdBu_r',\n",
    "               extent=epochs_MVP_Q.times[[0, -1, 0, -1]], vmin=0., vmax=1.)\n",
    "ax.set_xlabel('Testing Time (s)')\n",
    "ax.set_ylabel('Training Time (s)')\n",
    "ax.set_title('Temporal Generalization')\n",
    "ax.axvline(0, color='k')\n",
    "ax.axhline(0, color='k')\n",
    "plt.colorbar(im, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ring 1, 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_id_Q = np.arange(101,137,1).reshape(12, 3)\n",
    "R1_id = tmp_id_Q[[0,1,2,3],:].ravel()\n",
    "R2_id = tmp_id_Q[[4,5,6,7],:].ravel()\n",
    "R3_id = tmp_id_Q[[8,9,10,11],:].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_events_R = mne.merge_events(events, R1_id, 1)\n",
    "new_events_R = mne.merge_events(new_events_R, R2_id, 2)\n",
    "new_events_R = mne.merge_events(new_events_R, R3_id, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2424 matching events found\n",
      "0 projection items activated\n",
      "Loading data for 2424 events and 251 original time points ...\n",
      "    Rejecting  epoch based on EOG : [u'EOG003']\n",
      "    Rejecting  epoch based on EOG : [u'EOG003']\n",
      "2 bad epochs dropped\n",
      "2424 matching events found\n",
      "0 projection items activated\n",
      "Loading data for 2424 events and 251 original time points ...\n",
      "    Rejecting  epoch based on EOG : [u'EOG003']\n",
      "1 bad epochs dropped\n",
      "2424 matching events found\n",
      "0 projection items activated\n",
      "Loading data for 2424 events and 251 original time points ...\n",
      "    Rejecting  epoch based on EOG : [u'EOG003']\n",
      "    Rejecting  epoch based on EOG : [u'EOG003']\n",
      "2 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "new_event_R_id13 = dict(R1=1, R3=3)\n",
    "epochs_MVP_R13 = mne.Epochs(raw = raw, events = new_events_R,event_id = new_event_R_id13, tmin = tmin, tmax = tmax, proj=True,\n",
    "                     baseline=None, detrend = 0, preload=True,\n",
    "                    reject=reject, decim=4)\n",
    "new_event_R_id12 = dict(R2=1, R3=2)\n",
    "epochs_MVP_R12 = mne.Epochs(raw = raw, events = new_events_R,event_id = new_event_R_id12, tmin = tmin, tmax = tmax, proj=True,\n",
    "                     baseline=None, detrend = 0, preload=True,\n",
    "                    reject=reject, decim=4)\n",
    "new_event_R_id23 = dict(R2=1, R3=3)\n",
    "epochs_MVP_R23 = mne.Epochs(raw = raw, events = new_events_R,event_id = new_event_R_id23, tmin = tmin, tmax = tmax, proj=True,\n",
    "                     baseline=None, detrend = 0, preload=True,\n",
    "                    reject=reject, decim=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X13 = epochs_MVP_R13.get_data()  # MEG signals: n_epochs, n_channels, n_times\n",
    "y13 = epochs_MVP_R13.events[:, 2]  # target\n",
    "X12 = epochs_MVP_R12.get_data()  # MEG signals: n_epochs, n_channels, n_times\n",
    "y12 = epochs_MVP_R12.events[:, 2]  # target\n",
    "X23 = epochs_MVP_R23.get_data()  # MEG signals: n_epochs, n_channels, n_times\n",
    "y23 = epochs_MVP_R23.events[:, 2]  # target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:   14.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    8.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   23.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   23.1s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   18.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   18.3s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:   10.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    9.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   19.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   19.4s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   20.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   20.4s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    9.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    8.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   17.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   17.8s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   17.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   18.0s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    9.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    9.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   18.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   18.9s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   18.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   18.6s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    7.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   13.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   13.7s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    6.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   13.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   13.5s finished\n",
      "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  2.1min finished\n",
      "/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:   12.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:   11.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   22.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   22.5s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   21.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   21.6s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    8.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    8.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   17.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   17.1s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   18.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   18.4s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    9.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    9.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   18.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   18.2s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   18.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   18.0s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:   10.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:   12.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   20.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   20.6s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   20.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   20.5s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    7.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   13.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   13.9s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    6.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   12.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   12.0s finished\n",
      "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  2.0min finished\n",
      "/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    8.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    8.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   17.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   17.5s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   17.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   17.0s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    8.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    8.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   17.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   17.0s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   18.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   18.7s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    9.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:   10.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   18.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   18.9s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   18.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   18.8s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    8.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    9.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   20.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   20.6s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   21.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   21.6s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    8.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.6s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    6.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   14.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   14.9s finished\n",
      "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  2.0min finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define the Temporal Generalization object\n",
    "time_gen = GeneralizingEstimator(clf, n_jobs=2, scoring=scoring_function1)\n",
    "\n",
    "# 13\n",
    "scores13 = cross_val_multiscore(time_gen, X13, y13, cv=5, n_jobs=2)\n",
    "\n",
    "# Mean scores across cross-validation splits\n",
    "scores13 = np.mean(scores13, axis=0)\n",
    "\n",
    "# 12\n",
    "scores12 = cross_val_multiscore(time_gen, X12, y12, cv=5, n_jobs=2)\n",
    "\n",
    "# Mean scores across cross-validation splits\n",
    "scores12 = np.mean(scores12, axis=0)\n",
    "\n",
    "# 12\n",
    "scores23 = cross_val_multiscore(time_gen, X23, y23, cv=5, n_jobs=2)\n",
    "\n",
    "# Mean scores across cross-validation splits\n",
    "scores23 = np.mean(scores23, axis=0)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "\n",
    "im = ax.imshow(scores13, interpolation='lanczos', origin='lower', cmap='RdBu_r',\n",
    "               extent=epochs_MVP_R13.times[[0, -1, 0, -1]], vmin=0., vmax=1.)\n",
    "ax.set_xlabel('Testing Time (s)')\n",
    "ax.set_ylabel('Training Time (s)')\n",
    "ax.set_title('Temporal Generalization R1 and R2')\n",
    "ax.axvline(0, color='k')\n",
    "ax.axhline(0, color='k')\n",
    "plt.colorbar(im, ax=ax)\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "im = ax.imshow(scores12, interpolation='lanczos', origin='lower', cmap='RdBu_r',\n",
    "               extent=epochs_MVP_R13.times[[0, -1, 0, -1]], vmin=0., vmax=1.)\n",
    "ax.set_xlabel('Testing Time (s)')\n",
    "ax.set_ylabel('Training Time (s)')\n",
    "ax.set_title('Temporal Generalization R1 and R2')\n",
    "ax.axvline(0, color='k')\n",
    "ax.axhline(0, color='k')\n",
    "plt.colorbar(im, ax=ax)\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "im = ax.imshow(scores23, interpolation='lanczos', origin='lower', cmap='RdBu_r',\n",
    "               extent=epochs_MVP_R23.times[[0, -1, 0, -1]], vmin=0., vmax=1.)\n",
    "ax.set_xlabel('Testing Time (s)')\n",
    "ax.set_ylabel('Training Time (s)')\n",
    "ax.set_title('Temporal Generalization R2 and R3')\n",
    "ax.axvline(0, color='k')\n",
    "ax.axhline(0, color='k')\n",
    "plt.colorbar(im, ax=ax)\n",
    "plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the diagonal (it's exactly the same as the time-by-time decoding above)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(epochs_MVP_R13.times, np.diag(scores13), label='R1 vs R3')\n",
    "\n",
    "# Plot the diagonal (it's exactly the same as the time-by-time decoding above)\n",
    "\n",
    "ax.plot(epochs_MVP_R12.times, np.diag(scores12), label='R1 vs R2')\n",
    "\n",
    "\n",
    "\n",
    "# Plot the diagonal (it's exactly the same as the time-by-time decoding above)\n",
    "\n",
    "ax.plot(epochs_MVP_R23.times, np.diag(scores23), label='R2 vs R3')\n",
    "ax.axhline(.5, color='k', linestyle='--', label='chance')\n",
    "ax.set_xlabel('Times')\n",
    "ax.set_ylabel('AUC')\n",
    "ax.legend()\n",
    "ax.axvline(.0, color='k', linestyle='-')\n",
    "ax.set_title('Decoding MEG sensors over time Rings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadrants vs eachother "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_id_Q = np.arange(101,137,1).reshape(12, 3)\n",
    "Q1_id = tmp_id_Q[[0,4,8],:].ravel()\n",
    "Q2_id = tmp_id_Q[[1,5,9],:].ravel()\n",
    "Q3_id = tmp_id_Q[[2,6,10],:].ravel()\n",
    "Q4_id = tmp_id_Q[[3,7,11],:].ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_events_Q = mne.merge_events(events, Q1_id, 1)\n",
    "new_events_Q = mne.merge_events(new_events_Q, Q2_id, 2)\n",
    "new_events_Q = mne.merge_events(new_events_Q, Q3_id, 3)\n",
    "new_events_Q = mne.merge_events(new_events_Q, Q4_id, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1818 matching events found\n",
      "0 projection items activated\n",
      "Loading data for 1818 events and 251 original time points ...\n",
      "0 bad epochs dropped\n",
      "1818 matching events found\n",
      "0 projection items activated\n",
      "Loading data for 1818 events and 251 original time points ...\n",
      "0 bad epochs dropped\n",
      "1818 matching events found\n",
      "0 projection items activated\n",
      "Loading data for 1818 events and 251 original time points ...\n",
      "0 bad epochs dropped\n",
      "1818 matching events found\n",
      "0 projection items activated\n",
      "Loading data for 1818 events and 251 original time points ...\n",
      "0 bad epochs dropped\n",
      "1818 matching events found\n",
      "0 projection items activated\n",
      "Loading data for 1818 events and 251 original time points ...\n",
      "0 bad epochs dropped\n",
      "1818 matching events found\n",
      "0 projection items activated\n",
      "Loading data for 1818 events and 251 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "picks = mne.pick_types(raw.info, meg=True, eog=False, misc=False)\n",
    "\n",
    "\n",
    "\n",
    "new_event_Q12_id = dict(Q1=1, Q2=2)\n",
    "epochs_MVP_Q12 = mne.Epochs(raw = raw, events = new_events_Q, event_id = new_event_Q12_id, tmin = tmin, tmax = tmax, proj=True,\n",
    "                     baseline=None, detrend = 0, preload=True,\n",
    "                    reject=reject, decim=4, picks = picks)\n",
    "\n",
    "new_event_Q13_id = dict(Q1=1, Q3=3)\n",
    "epochs_MVP_Q13 = mne.Epochs(raw = raw, events = new_events_Q, event_id = new_event_Q13_id, tmin = tmin, tmax = tmax, proj=True,\n",
    "                     baseline=None, detrend = 0, preload=True,\n",
    "                    reject=reject, decim=4, picks = picks)\n",
    "\n",
    "new_event_Q14_id = dict(Q1=1, Q4=4)\n",
    "epochs_MVP_Q14 = mne.Epochs(raw = raw, events = new_events_Q, event_id = new_event_Q14_id, tmin = tmin, tmax = tmax, proj=True,\n",
    "                     baseline=None, detrend = 0, preload=True,\n",
    "                    reject=reject, decim=4, picks = picks)\n",
    "\n",
    "new_event_Q23_id = dict(Q2=2, Q3=3)\n",
    "epochs_MVP_Q23 = mne.Epochs(raw = raw, events = new_events_Q, event_id = new_event_Q23_id, tmin = tmin, tmax = tmax, proj=True,\n",
    "                     baseline=None, detrend = 0, preload=True,\n",
    "                    reject=reject, decim=4, picks = picks)\n",
    "\n",
    "new_event_Q24_id = dict(Q2=2, Q4=4)\n",
    "epochs_MVP_Q24 = mne.Epochs(raw = raw, events = new_events_Q, event_id = new_event_Q24_id, tmin = tmin, tmax = tmax, proj=True,\n",
    "                     baseline=None, detrend = 0, preload=True,\n",
    "                    reject=reject, decim=4, picks = picks)\n",
    "\n",
    "new_event_Q34_id = dict(Q3=3, Q4=4)\n",
    "epochs_MVP_Q34 = mne.Epochs(raw = raw, events = new_events_Q, event_id = new_event_Q34_id, tmin = tmin, tmax = tmax, proj=True,\n",
    "                     baseline=None, detrend = 0, preload=True,\n",
    "                    reject=reject, decim=4, picks = picks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XQ12 = epochs_MVP_Q12.get_data()  # MEG signals: n_epochs, n_channels, n_times\n",
    "yQ12 = epochs_MVP_Q12.events[:, 2]  # target\n",
    "XQ13 = epochs_MVP_Q13.get_data()  # MEG signals: n_epochs, n_channels, n_times\n",
    "yQ13 = epochs_MVP_Q13.events[:, 2]  # target\n",
    "XQ14 = epochs_MVP_Q14.get_data()  # MEG signals: n_epochs, n_channels, n_times\n",
    "yQ14 = epochs_MVP_Q14.events[:, 2]  # target\n",
    "XQ23 = epochs_MVP_Q23.get_data()  # MEG signals: n_epochs, n_channels, n_times\n",
    "yQ23 = epochs_MVP_Q23.events[:, 2]  # target\n",
    "XQ24 = epochs_MVP_Q24.get_data()  # MEG signals: n_epochs, n_channels, n_times\n",
    "yQ24 = epochs_MVP_Q24.events[:, 2]  # target\n",
    "XQ34 = epochs_MVP_Q34.get_data()  # MEG signals: n_epochs, n_channels, n_times\n",
    "yQ34 = epochs_MVP_Q34.events[:, 2]  # target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    8.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    7.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.6s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   14.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   14.8s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    6.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    6.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   13.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   13.6s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   14.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   14.6s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    8.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    7.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.5s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.5s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    6.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    6.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   13.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   13.3s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   13.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   13.1s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    5.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   11.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   11.2s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    4.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    9.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    9.3s finished\n",
      "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.5min finished\n",
      "/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    8.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    8.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   17.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   17.1s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   16.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   16.6s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    7.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    7.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   14.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   14.7s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.7s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    7.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    8.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.5s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   16.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   16.1s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    7.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    7.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.0s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   14.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   14.9s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    6.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   12.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   12.0s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    5.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   11.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   11.0s finished\n",
      "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.6min finished\n",
      "/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    9.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    8.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   19.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   19.3s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   18.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   18.7s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    8.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    7.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.2s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.3s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    7.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    8.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   16.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   16.2s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   17.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   17.2s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    8.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    7.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.7s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.4s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    6.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   11.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   11.5s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    7.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.2s finished\n",
      "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    9.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:   10.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   19.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   19.5s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   18.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   18.8s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    9.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    9.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   17.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   17.5s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   17.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   17.7s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    8.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    7.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.8s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   16.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   16.4s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    8.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    7.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.9s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   14.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.0s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    6.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   14.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   14.4s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    5.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   10.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   10.6s finished\n",
      "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.7min finished\n",
      "/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    8.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    7.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.6s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.5s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    7.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    7.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   14.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   14.3s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.1s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    8.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    7.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.7s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.6s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    7.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    7.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.5s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   16.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   16.3s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    6.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   11.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   11.7s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    5.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   11.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   11.7s finished\n",
      "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.6min finished\n",
      "/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    8.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    8.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   16.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   16.2s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   16.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   16.3s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    7.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    7.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   14.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   14.1s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   15.8s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    7.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    8.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   17.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   17.7s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   19.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   19.3s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:   10.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:   10.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   20.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   20.1s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   18.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   18.8s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    5.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   12.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   12.0s finished\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    6.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   11.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   11.0s finished\n",
      "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.7min finished\n"
     ]
    }
   ],
   "source": [
    "# define the Temporal Generalization object\n",
    "clf = make_pipeline(StandardScaler(), LinearModel(LogisticRegression()))\n",
    "\n",
    "time_gen = GeneralizingEstimator(clf, n_jobs=2, scoring=scoring_function1)\n",
    "\n",
    "# 12\n",
    "scoresQ12 = cross_val_multiscore(time_gen, XQ12, yQ12, cv=5, n_jobs=2)\n",
    "\n",
    "# Mean scores across cross-validation splits\n",
    "scoresQ12 = np.mean(scoresQ12, axis=0)\n",
    "\n",
    "# 13\n",
    "scoresQ13 = cross_val_multiscore(time_gen, XQ13, yQ13, cv=5, n_jobs=2)\n",
    "\n",
    "# Mean scores across cross-validation splits\n",
    "scoresQ13 = np.mean(scoresQ13, axis=0)\n",
    "\n",
    "# 14\n",
    "scoresQ14 = cross_val_multiscore(time_gen, XQ14, yQ14, cv=5, n_jobs=2)\n",
    "\n",
    "# Mean scores across cross-validation splits\n",
    "scoresQ14 = np.mean(scoresQ14, axis=0)\n",
    "\n",
    "# 23\n",
    "scoresQ23 = cross_val_multiscore(time_gen, XQ23, yQ23, cv=5, n_jobs=2)\n",
    "\n",
    "# Mean scores across cross-validation splits\n",
    "scoresQ23 = np.mean(scoresQ23, axis=0)\n",
    "\n",
    "# 24\n",
    "scoresQ24 = cross_val_multiscore(time_gen, XQ24, yQ24, cv=5, n_jobs=2)\n",
    "\n",
    "# Mean scores across cross-validation splits\n",
    "scoresQ24 = np.mean(scoresQ24, axis=0)\n",
    "\n",
    "# 34\n",
    "scoresQ34 = cross_val_multiscore(time_gen, XQ34, yQ34, cv=5, n_jobs=2)\n",
    "\n",
    "# Mean scores across cross-validation splits\n",
    "scoresQ34 = np.mean(scoresQ34, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the diagonal (it's exactly the same as the time-by-time decoding above)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(epochs_MVP_Q12.times, np.diag(scoresQ12), label='Q1 vs Q2')\n",
    "\n",
    "ax.plot(epochs_MVP_Q13.times, np.diag(scoresQ13), label='Q1 vs Q3')\n",
    "\n",
    "ax.plot(epochs_MVP_Q14.times, np.diag(scoresQ14), label='Q1 vs Q4')\n",
    "\n",
    "ax.plot(epochs_MVP_Q23.times, np.diag(scoresQ23), label='Q2 vs Q3')\n",
    "\n",
    "ax.plot(epochs_MVP_Q24.times, np.diag(scoresQ24), label='Q2 vs Q4')\n",
    "\n",
    "ax.plot(epochs_MVP_Q34.times, np.diag(scoresQ34), label='Q3 vs Q4')\n",
    "ax.axhline(.5, color='k', linestyle='--', label='chance')\n",
    "ax.set_xlabel('Times')\n",
    "ax.set_ylabel('AUC')\n",
    "ax.legend()\n",
    "ax.axvline(.0, color='k', linestyle='-')\n",
    "ax.set_title('Decoding MEG sensors over time in different quadrants')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "\n",
    "im = ax.imshow(scoresQ14, interpolation='lanczos', origin='lower', cmap='RdBu_r',\n",
    "               extent=epochs_MVP_Q14.times[[0, -1, 0, -1]], vmin=0., vmax=1.)\n",
    "ax.set_xlabel('Testing Time (s)')\n",
    "ax.set_ylabel('Training Time (s)')\n",
    "ax.set_title('Temporal Generalization Q1 and Q4')\n",
    "ax.axvline(0, color='k')\n",
    "ax.axhline(0, color='k')\n",
    "plt.colorbar(im, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "\n",
    "im = ax.imshow(scoresQ24, interpolation='lanczos', origin='lower', cmap='RdBu_r',\n",
    "               extent=epochs_MVP_Q24.times[[0, -1, 0, -1]], vmin=0., vmax=1.)\n",
    "ax.set_xlabel('Testing Time (s)')\n",
    "ax.set_ylabel('Training Time (s)')\n",
    "ax.set_title('Temporal Generalization Q2 and Q4')\n",
    "ax.axvline(0, color='k')\n",
    "ax.axhline(0, color='k')\n",
    "plt.colorbar(im, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
